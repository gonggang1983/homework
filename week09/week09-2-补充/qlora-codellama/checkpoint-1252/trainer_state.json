{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1252,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0159824193387274,
      "grad_norm": 0.14202846586704254,
      "learning_rate": 0.00019856230031948884,
      "loss": 1.8484,
      "step": 20
    },
    {
      "epoch": 0.0319648386774548,
      "grad_norm": 0.056461263447999954,
      "learning_rate": 0.00019696485623003196,
      "loss": 0.1817,
      "step": 40
    },
    {
      "epoch": 0.0479472580161822,
      "grad_norm": 0.05758899450302124,
      "learning_rate": 0.0001953674121405751,
      "loss": 0.1498,
      "step": 60
    },
    {
      "epoch": 0.0639296773549096,
      "grad_norm": 0.05023254454135895,
      "learning_rate": 0.0001937699680511182,
      "loss": 0.1474,
      "step": 80
    },
    {
      "epoch": 0.079912096693637,
      "grad_norm": 0.04867757856845856,
      "learning_rate": 0.00019217252396166133,
      "loss": 0.16,
      "step": 100
    },
    {
      "epoch": 0.0958945160323644,
      "grad_norm": 0.07116024941205978,
      "learning_rate": 0.00019057507987220448,
      "loss": 0.1435,
      "step": 120
    },
    {
      "epoch": 0.11187693537109179,
      "grad_norm": 0.05584539845585823,
      "learning_rate": 0.0001889776357827476,
      "loss": 0.1405,
      "step": 140
    },
    {
      "epoch": 0.1278593547098192,
      "grad_norm": 0.05190632864832878,
      "learning_rate": 0.00018738019169329076,
      "loss": 0.1351,
      "step": 160
    },
    {
      "epoch": 0.1438417740485466,
      "grad_norm": 0.0557708777487278,
      "learning_rate": 0.00018578274760383388,
      "loss": 0.1375,
      "step": 180
    },
    {
      "epoch": 0.159824193387274,
      "grad_norm": 0.05079665780067444,
      "learning_rate": 0.00018418530351437703,
      "loss": 0.1296,
      "step": 200
    },
    {
      "epoch": 0.1758066127260014,
      "grad_norm": 0.060494791716337204,
      "learning_rate": 0.00018258785942492015,
      "loss": 0.1305,
      "step": 220
    },
    {
      "epoch": 0.1917890320647288,
      "grad_norm": 0.047875676304101944,
      "learning_rate": 0.00018099041533546325,
      "loss": 0.1221,
      "step": 240
    },
    {
      "epoch": 0.2077714514034562,
      "grad_norm": 0.04958285391330719,
      "learning_rate": 0.0001793929712460064,
      "loss": 0.123,
      "step": 260
    },
    {
      "epoch": 0.22375387074218359,
      "grad_norm": 0.04882783442735672,
      "learning_rate": 0.00017779552715654952,
      "loss": 0.1257,
      "step": 280
    },
    {
      "epoch": 0.239736290080911,
      "grad_norm": 0.049439553171396255,
      "learning_rate": 0.00017619808306709267,
      "loss": 0.1306,
      "step": 300
    },
    {
      "epoch": 0.2557187094196384,
      "grad_norm": 0.04803489148616791,
      "learning_rate": 0.0001746006389776358,
      "loss": 0.1263,
      "step": 320
    },
    {
      "epoch": 0.2717011287583658,
      "grad_norm": 0.046562228351831436,
      "learning_rate": 0.00017300319488817894,
      "loss": 0.1227,
      "step": 340
    },
    {
      "epoch": 0.2876835480970932,
      "grad_norm": 0.04353240877389908,
      "learning_rate": 0.00017140575079872207,
      "loss": 0.1237,
      "step": 360
    },
    {
      "epoch": 0.3036659674358206,
      "grad_norm": 0.04234357550740242,
      "learning_rate": 0.0001698083067092652,
      "loss": 0.1331,
      "step": 380
    },
    {
      "epoch": 0.319648386774548,
      "grad_norm": 0.05317840352654457,
      "learning_rate": 0.0001682108626198083,
      "loss": 0.1277,
      "step": 400
    },
    {
      "epoch": 0.3356308061132754,
      "grad_norm": 0.0507391057908535,
      "learning_rate": 0.00016661341853035143,
      "loss": 0.128,
      "step": 420
    },
    {
      "epoch": 0.3516132254520028,
      "grad_norm": 0.04620761796832085,
      "learning_rate": 0.00016501597444089458,
      "loss": 0.1264,
      "step": 440
    },
    {
      "epoch": 0.3675956447907302,
      "grad_norm": 0.04164059832692146,
      "learning_rate": 0.0001634185303514377,
      "loss": 0.1234,
      "step": 460
    },
    {
      "epoch": 0.3835780641294576,
      "grad_norm": 0.049304284155368805,
      "learning_rate": 0.00016182108626198086,
      "loss": 0.1266,
      "step": 480
    },
    {
      "epoch": 0.399560483468185,
      "grad_norm": 0.04870219528675079,
      "learning_rate": 0.00016022364217252398,
      "loss": 0.1264,
      "step": 500
    },
    {
      "epoch": 0.4155429028069124,
      "grad_norm": 0.04470941424369812,
      "learning_rate": 0.0001586261980830671,
      "loss": 0.1289,
      "step": 520
    },
    {
      "epoch": 0.4315253221456398,
      "grad_norm": 0.0508938804268837,
      "learning_rate": 0.00015702875399361022,
      "loss": 0.1249,
      "step": 540
    },
    {
      "epoch": 0.44750774148436717,
      "grad_norm": 0.044369589537382126,
      "learning_rate": 0.00015543130990415335,
      "loss": 0.1296,
      "step": 560
    },
    {
      "epoch": 0.4634901608230946,
      "grad_norm": 0.04527302458882332,
      "learning_rate": 0.0001538338658146965,
      "loss": 0.1327,
      "step": 580
    },
    {
      "epoch": 0.479472580161822,
      "grad_norm": 0.03762517496943474,
      "learning_rate": 0.00015223642172523962,
      "loss": 0.1224,
      "step": 600
    },
    {
      "epoch": 0.4954549995005494,
      "grad_norm": 0.039145562797784805,
      "learning_rate": 0.00015063897763578277,
      "loss": 0.1257,
      "step": 620
    },
    {
      "epoch": 0.5114374188392768,
      "grad_norm": 0.04480753839015961,
      "learning_rate": 0.0001490415335463259,
      "loss": 0.1236,
      "step": 640
    },
    {
      "epoch": 0.5274198381780042,
      "grad_norm": 0.04307643324136734,
      "learning_rate": 0.00014744408945686902,
      "loss": 0.1329,
      "step": 660
    },
    {
      "epoch": 0.5434022575167315,
      "grad_norm": 0.04659426957368851,
      "learning_rate": 0.00014584664536741214,
      "loss": 0.1192,
      "step": 680
    },
    {
      "epoch": 0.559384676855459,
      "grad_norm": 0.04256465658545494,
      "learning_rate": 0.00014424920127795526,
      "loss": 0.1234,
      "step": 700
    },
    {
      "epoch": 0.5753670961941864,
      "grad_norm": 0.03997394070029259,
      "learning_rate": 0.0001426517571884984,
      "loss": 0.1233,
      "step": 720
    },
    {
      "epoch": 0.5913495155329138,
      "grad_norm": 0.04977554827928543,
      "learning_rate": 0.00014105431309904153,
      "loss": 0.1222,
      "step": 740
    },
    {
      "epoch": 0.6073319348716412,
      "grad_norm": 0.04197286441922188,
      "learning_rate": 0.00013945686900958468,
      "loss": 0.1315,
      "step": 760
    },
    {
      "epoch": 0.6233143542103686,
      "grad_norm": 0.045013491064310074,
      "learning_rate": 0.0001378594249201278,
      "loss": 0.1301,
      "step": 780
    },
    {
      "epoch": 0.639296773549096,
      "grad_norm": 0.04455012083053589,
      "learning_rate": 0.00013626198083067093,
      "loss": 0.124,
      "step": 800
    },
    {
      "epoch": 0.6552791928878234,
      "grad_norm": 0.04684865102171898,
      "learning_rate": 0.00013466453674121405,
      "loss": 0.125,
      "step": 820
    },
    {
      "epoch": 0.6712616122265508,
      "grad_norm": 0.0423286072909832,
      "learning_rate": 0.00013306709265175718,
      "loss": 0.1315,
      "step": 840
    },
    {
      "epoch": 0.6872440315652782,
      "grad_norm": 0.040620919317007065,
      "learning_rate": 0.00013146964856230033,
      "loss": 0.1195,
      "step": 860
    },
    {
      "epoch": 0.7032264509040056,
      "grad_norm": 0.04072757810354233,
      "learning_rate": 0.00012987220447284345,
      "loss": 0.1266,
      "step": 880
    },
    {
      "epoch": 0.719208870242733,
      "grad_norm": 0.04139820486307144,
      "learning_rate": 0.0001282747603833866,
      "loss": 0.1199,
      "step": 900
    },
    {
      "epoch": 0.7351912895814604,
      "grad_norm": 0.04584073647856712,
      "learning_rate": 0.00012667731629392972,
      "loss": 0.1255,
      "step": 920
    },
    {
      "epoch": 0.7511737089201878,
      "grad_norm": 0.03656190633773804,
      "learning_rate": 0.00012507987220447287,
      "loss": 0.1213,
      "step": 940
    },
    {
      "epoch": 0.7671561282589152,
      "grad_norm": 0.03583957999944687,
      "learning_rate": 0.00012348242811501597,
      "loss": 0.1197,
      "step": 960
    },
    {
      "epoch": 0.7831385475976426,
      "grad_norm": 0.0482972115278244,
      "learning_rate": 0.0001218849840255591,
      "loss": 0.1291,
      "step": 980
    },
    {
      "epoch": 0.79912096693637,
      "grad_norm": 0.04426395148038864,
      "learning_rate": 0.00012028753993610224,
      "loss": 0.1268,
      "step": 1000
    },
    {
      "epoch": 0.8151033862750974,
      "grad_norm": 0.036313388496637344,
      "learning_rate": 0.00011869009584664536,
      "loss": 0.1227,
      "step": 1020
    },
    {
      "epoch": 0.8310858056138248,
      "grad_norm": 0.03614654019474983,
      "learning_rate": 0.00011709265175718851,
      "loss": 0.1281,
      "step": 1040
    },
    {
      "epoch": 0.8470682249525522,
      "grad_norm": 0.041432902216911316,
      "learning_rate": 0.00011549520766773163,
      "loss": 0.1276,
      "step": 1060
    },
    {
      "epoch": 0.8630506442912796,
      "grad_norm": 0.054052144289016724,
      "learning_rate": 0.00011389776357827477,
      "loss": 0.1306,
      "step": 1080
    },
    {
      "epoch": 0.879033063630007,
      "grad_norm": 0.04127110540866852,
      "learning_rate": 0.0001123003194888179,
      "loss": 0.1172,
      "step": 1100
    },
    {
      "epoch": 0.8950154829687343,
      "grad_norm": 0.036218881607055664,
      "learning_rate": 0.00011070287539936102,
      "loss": 0.1363,
      "step": 1120
    },
    {
      "epoch": 0.9109979023074618,
      "grad_norm": 0.042277418076992035,
      "learning_rate": 0.00010910543130990417,
      "loss": 0.1221,
      "step": 1140
    },
    {
      "epoch": 0.9269803216461892,
      "grad_norm": 0.04434940218925476,
      "learning_rate": 0.00010750798722044728,
      "loss": 0.1251,
      "step": 1160
    },
    {
      "epoch": 0.9429627409849166,
      "grad_norm": 0.034970708191394806,
      "learning_rate": 0.00010591054313099043,
      "loss": 0.126,
      "step": 1180
    },
    {
      "epoch": 0.958945160323644,
      "grad_norm": 0.037158891558647156,
      "learning_rate": 0.00010431309904153355,
      "loss": 0.1167,
      "step": 1200
    },
    {
      "epoch": 0.9749275796623714,
      "grad_norm": 0.03745673969388008,
      "learning_rate": 0.00010271565495207669,
      "loss": 0.1291,
      "step": 1220
    },
    {
      "epoch": 0.9909099990010988,
      "grad_norm": 0.04053658992052078,
      "learning_rate": 0.00010111821086261981,
      "loss": 0.1223,
      "step": 1240
    }
  ],
  "logging_steps": 20,
  "max_steps": 2504,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.074376994614149e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
