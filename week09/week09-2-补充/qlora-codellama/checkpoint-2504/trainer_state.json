{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 2504,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0159824193387274,
      "grad_norm": 0.14202846586704254,
      "learning_rate": 0.00019856230031948884,
      "loss": 1.8484,
      "step": 20
    },
    {
      "epoch": 0.0319648386774548,
      "grad_norm": 0.056461263447999954,
      "learning_rate": 0.00019696485623003196,
      "loss": 0.1817,
      "step": 40
    },
    {
      "epoch": 0.0479472580161822,
      "grad_norm": 0.05758899450302124,
      "learning_rate": 0.0001953674121405751,
      "loss": 0.1498,
      "step": 60
    },
    {
      "epoch": 0.0639296773549096,
      "grad_norm": 0.05023254454135895,
      "learning_rate": 0.0001937699680511182,
      "loss": 0.1474,
      "step": 80
    },
    {
      "epoch": 0.079912096693637,
      "grad_norm": 0.04867757856845856,
      "learning_rate": 0.00019217252396166133,
      "loss": 0.16,
      "step": 100
    },
    {
      "epoch": 0.0958945160323644,
      "grad_norm": 0.07116024941205978,
      "learning_rate": 0.00019057507987220448,
      "loss": 0.1435,
      "step": 120
    },
    {
      "epoch": 0.11187693537109179,
      "grad_norm": 0.05584539845585823,
      "learning_rate": 0.0001889776357827476,
      "loss": 0.1405,
      "step": 140
    },
    {
      "epoch": 0.1278593547098192,
      "grad_norm": 0.05190632864832878,
      "learning_rate": 0.00018738019169329076,
      "loss": 0.1351,
      "step": 160
    },
    {
      "epoch": 0.1438417740485466,
      "grad_norm": 0.0557708777487278,
      "learning_rate": 0.00018578274760383388,
      "loss": 0.1375,
      "step": 180
    },
    {
      "epoch": 0.159824193387274,
      "grad_norm": 0.05079665780067444,
      "learning_rate": 0.00018418530351437703,
      "loss": 0.1296,
      "step": 200
    },
    {
      "epoch": 0.1758066127260014,
      "grad_norm": 0.060494791716337204,
      "learning_rate": 0.00018258785942492015,
      "loss": 0.1305,
      "step": 220
    },
    {
      "epoch": 0.1917890320647288,
      "grad_norm": 0.047875676304101944,
      "learning_rate": 0.00018099041533546325,
      "loss": 0.1221,
      "step": 240
    },
    {
      "epoch": 0.2077714514034562,
      "grad_norm": 0.04958285391330719,
      "learning_rate": 0.0001793929712460064,
      "loss": 0.123,
      "step": 260
    },
    {
      "epoch": 0.22375387074218359,
      "grad_norm": 0.04882783442735672,
      "learning_rate": 0.00017779552715654952,
      "loss": 0.1257,
      "step": 280
    },
    {
      "epoch": 0.239736290080911,
      "grad_norm": 0.049439553171396255,
      "learning_rate": 0.00017619808306709267,
      "loss": 0.1306,
      "step": 300
    },
    {
      "epoch": 0.2557187094196384,
      "grad_norm": 0.04803489148616791,
      "learning_rate": 0.0001746006389776358,
      "loss": 0.1263,
      "step": 320
    },
    {
      "epoch": 0.2717011287583658,
      "grad_norm": 0.046562228351831436,
      "learning_rate": 0.00017300319488817894,
      "loss": 0.1227,
      "step": 340
    },
    {
      "epoch": 0.2876835480970932,
      "grad_norm": 0.04353240877389908,
      "learning_rate": 0.00017140575079872207,
      "loss": 0.1237,
      "step": 360
    },
    {
      "epoch": 0.3036659674358206,
      "grad_norm": 0.04234357550740242,
      "learning_rate": 0.0001698083067092652,
      "loss": 0.1331,
      "step": 380
    },
    {
      "epoch": 0.319648386774548,
      "grad_norm": 0.05317840352654457,
      "learning_rate": 0.0001682108626198083,
      "loss": 0.1277,
      "step": 400
    },
    {
      "epoch": 0.3356308061132754,
      "grad_norm": 0.0507391057908535,
      "learning_rate": 0.00016661341853035143,
      "loss": 0.128,
      "step": 420
    },
    {
      "epoch": 0.3516132254520028,
      "grad_norm": 0.04620761796832085,
      "learning_rate": 0.00016501597444089458,
      "loss": 0.1264,
      "step": 440
    },
    {
      "epoch": 0.3675956447907302,
      "grad_norm": 0.04164059832692146,
      "learning_rate": 0.0001634185303514377,
      "loss": 0.1234,
      "step": 460
    },
    {
      "epoch": 0.3835780641294576,
      "grad_norm": 0.049304284155368805,
      "learning_rate": 0.00016182108626198086,
      "loss": 0.1266,
      "step": 480
    },
    {
      "epoch": 0.399560483468185,
      "grad_norm": 0.04870219528675079,
      "learning_rate": 0.00016022364217252398,
      "loss": 0.1264,
      "step": 500
    },
    {
      "epoch": 0.4155429028069124,
      "grad_norm": 0.04470941424369812,
      "learning_rate": 0.0001586261980830671,
      "loss": 0.1289,
      "step": 520
    },
    {
      "epoch": 0.4315253221456398,
      "grad_norm": 0.0508938804268837,
      "learning_rate": 0.00015702875399361022,
      "loss": 0.1249,
      "step": 540
    },
    {
      "epoch": 0.44750774148436717,
      "grad_norm": 0.044369589537382126,
      "learning_rate": 0.00015543130990415335,
      "loss": 0.1296,
      "step": 560
    },
    {
      "epoch": 0.4634901608230946,
      "grad_norm": 0.04527302458882332,
      "learning_rate": 0.0001538338658146965,
      "loss": 0.1327,
      "step": 580
    },
    {
      "epoch": 0.479472580161822,
      "grad_norm": 0.03762517496943474,
      "learning_rate": 0.00015223642172523962,
      "loss": 0.1224,
      "step": 600
    },
    {
      "epoch": 0.4954549995005494,
      "grad_norm": 0.039145562797784805,
      "learning_rate": 0.00015063897763578277,
      "loss": 0.1257,
      "step": 620
    },
    {
      "epoch": 0.5114374188392768,
      "grad_norm": 0.04480753839015961,
      "learning_rate": 0.0001490415335463259,
      "loss": 0.1236,
      "step": 640
    },
    {
      "epoch": 0.5274198381780042,
      "grad_norm": 0.04307643324136734,
      "learning_rate": 0.00014744408945686902,
      "loss": 0.1329,
      "step": 660
    },
    {
      "epoch": 0.5434022575167315,
      "grad_norm": 0.04659426957368851,
      "learning_rate": 0.00014584664536741214,
      "loss": 0.1192,
      "step": 680
    },
    {
      "epoch": 0.559384676855459,
      "grad_norm": 0.04256465658545494,
      "learning_rate": 0.00014424920127795526,
      "loss": 0.1234,
      "step": 700
    },
    {
      "epoch": 0.5753670961941864,
      "grad_norm": 0.03997394070029259,
      "learning_rate": 0.0001426517571884984,
      "loss": 0.1233,
      "step": 720
    },
    {
      "epoch": 0.5913495155329138,
      "grad_norm": 0.04977554827928543,
      "learning_rate": 0.00014105431309904153,
      "loss": 0.1222,
      "step": 740
    },
    {
      "epoch": 0.6073319348716412,
      "grad_norm": 0.04197286441922188,
      "learning_rate": 0.00013945686900958468,
      "loss": 0.1315,
      "step": 760
    },
    {
      "epoch": 0.6233143542103686,
      "grad_norm": 0.045013491064310074,
      "learning_rate": 0.0001378594249201278,
      "loss": 0.1301,
      "step": 780
    },
    {
      "epoch": 0.639296773549096,
      "grad_norm": 0.04455012083053589,
      "learning_rate": 0.00013626198083067093,
      "loss": 0.124,
      "step": 800
    },
    {
      "epoch": 0.6552791928878234,
      "grad_norm": 0.04684865102171898,
      "learning_rate": 0.00013466453674121405,
      "loss": 0.125,
      "step": 820
    },
    {
      "epoch": 0.6712616122265508,
      "grad_norm": 0.0423286072909832,
      "learning_rate": 0.00013306709265175718,
      "loss": 0.1315,
      "step": 840
    },
    {
      "epoch": 0.6872440315652782,
      "grad_norm": 0.040620919317007065,
      "learning_rate": 0.00013146964856230033,
      "loss": 0.1195,
      "step": 860
    },
    {
      "epoch": 0.7032264509040056,
      "grad_norm": 0.04072757810354233,
      "learning_rate": 0.00012987220447284345,
      "loss": 0.1266,
      "step": 880
    },
    {
      "epoch": 0.719208870242733,
      "grad_norm": 0.04139820486307144,
      "learning_rate": 0.0001282747603833866,
      "loss": 0.1199,
      "step": 900
    },
    {
      "epoch": 0.7351912895814604,
      "grad_norm": 0.04584073647856712,
      "learning_rate": 0.00012667731629392972,
      "loss": 0.1255,
      "step": 920
    },
    {
      "epoch": 0.7511737089201878,
      "grad_norm": 0.03656190633773804,
      "learning_rate": 0.00012507987220447287,
      "loss": 0.1213,
      "step": 940
    },
    {
      "epoch": 0.7671561282589152,
      "grad_norm": 0.03583957999944687,
      "learning_rate": 0.00012348242811501597,
      "loss": 0.1197,
      "step": 960
    },
    {
      "epoch": 0.7831385475976426,
      "grad_norm": 0.0482972115278244,
      "learning_rate": 0.0001218849840255591,
      "loss": 0.1291,
      "step": 980
    },
    {
      "epoch": 0.79912096693637,
      "grad_norm": 0.04426395148038864,
      "learning_rate": 0.00012028753993610224,
      "loss": 0.1268,
      "step": 1000
    },
    {
      "epoch": 0.8151033862750974,
      "grad_norm": 0.036313388496637344,
      "learning_rate": 0.00011869009584664536,
      "loss": 0.1227,
      "step": 1020
    },
    {
      "epoch": 0.8310858056138248,
      "grad_norm": 0.03614654019474983,
      "learning_rate": 0.00011709265175718851,
      "loss": 0.1281,
      "step": 1040
    },
    {
      "epoch": 0.8470682249525522,
      "grad_norm": 0.041432902216911316,
      "learning_rate": 0.00011549520766773163,
      "loss": 0.1276,
      "step": 1060
    },
    {
      "epoch": 0.8630506442912796,
      "grad_norm": 0.054052144289016724,
      "learning_rate": 0.00011389776357827477,
      "loss": 0.1306,
      "step": 1080
    },
    {
      "epoch": 0.879033063630007,
      "grad_norm": 0.04127110540866852,
      "learning_rate": 0.0001123003194888179,
      "loss": 0.1172,
      "step": 1100
    },
    {
      "epoch": 0.8950154829687343,
      "grad_norm": 0.036218881607055664,
      "learning_rate": 0.00011070287539936102,
      "loss": 0.1363,
      "step": 1120
    },
    {
      "epoch": 0.9109979023074618,
      "grad_norm": 0.042277418076992035,
      "learning_rate": 0.00010910543130990417,
      "loss": 0.1221,
      "step": 1140
    },
    {
      "epoch": 0.9269803216461892,
      "grad_norm": 0.04434940218925476,
      "learning_rate": 0.00010750798722044728,
      "loss": 0.1251,
      "step": 1160
    },
    {
      "epoch": 0.9429627409849166,
      "grad_norm": 0.034970708191394806,
      "learning_rate": 0.00010591054313099043,
      "loss": 0.126,
      "step": 1180
    },
    {
      "epoch": 0.958945160323644,
      "grad_norm": 0.037158891558647156,
      "learning_rate": 0.00010431309904153355,
      "loss": 0.1167,
      "step": 1200
    },
    {
      "epoch": 0.9749275796623714,
      "grad_norm": 0.03745673969388008,
      "learning_rate": 0.00010271565495207669,
      "loss": 0.1291,
      "step": 1220
    },
    {
      "epoch": 0.9909099990010988,
      "grad_norm": 0.04053658992052078,
      "learning_rate": 0.00010111821086261981,
      "loss": 0.1223,
      "step": 1240
    },
    {
      "epoch": 1.006392967735491,
      "grad_norm": 0.04153404384851456,
      "learning_rate": 9.952076677316294e-05,
      "loss": 0.1264,
      "step": 1260
    },
    {
      "epoch": 1.0223753870742183,
      "grad_norm": 0.03959665820002556,
      "learning_rate": 9.792332268370608e-05,
      "loss": 0.1235,
      "step": 1280
    },
    {
      "epoch": 1.0383578064129457,
      "grad_norm": 0.04593098163604736,
      "learning_rate": 9.63258785942492e-05,
      "loss": 0.1211,
      "step": 1300
    },
    {
      "epoch": 1.0543402257516732,
      "grad_norm": 0.04269411042332649,
      "learning_rate": 9.472843450479234e-05,
      "loss": 0.1265,
      "step": 1320
    },
    {
      "epoch": 1.0703226450904006,
      "grad_norm": 0.04397907108068466,
      "learning_rate": 9.313099041533548e-05,
      "loss": 0.1254,
      "step": 1340
    },
    {
      "epoch": 1.0863050644291279,
      "grad_norm": 0.04261883720755577,
      "learning_rate": 9.15335463258786e-05,
      "loss": 0.1183,
      "step": 1360
    },
    {
      "epoch": 1.1022874837678553,
      "grad_norm": 0.04117167368531227,
      "learning_rate": 8.993610223642172e-05,
      "loss": 0.1203,
      "step": 1380
    },
    {
      "epoch": 1.1182699031065828,
      "grad_norm": 0.04841507598757744,
      "learning_rate": 8.833865814696486e-05,
      "loss": 0.1118,
      "step": 1400
    },
    {
      "epoch": 1.13425232244531,
      "grad_norm": 0.05162009596824646,
      "learning_rate": 8.6741214057508e-05,
      "loss": 0.1251,
      "step": 1420
    },
    {
      "epoch": 1.1502347417840375,
      "grad_norm": 0.039055097848176956,
      "learning_rate": 8.514376996805112e-05,
      "loss": 0.1221,
      "step": 1440
    },
    {
      "epoch": 1.166217161122765,
      "grad_norm": 0.038139600306749344,
      "learning_rate": 8.354632587859425e-05,
      "loss": 0.1219,
      "step": 1460
    },
    {
      "epoch": 1.1821995804614924,
      "grad_norm": 0.04753672704100609,
      "learning_rate": 8.194888178913739e-05,
      "loss": 0.119,
      "step": 1480
    },
    {
      "epoch": 1.1981819998002197,
      "grad_norm": 0.048946563154459,
      "learning_rate": 8.035143769968051e-05,
      "loss": 0.1293,
      "step": 1500
    },
    {
      "epoch": 1.2141644191389471,
      "grad_norm": 0.04278728365898132,
      "learning_rate": 7.875399361022364e-05,
      "loss": 0.1177,
      "step": 1520
    },
    {
      "epoch": 1.2301468384776746,
      "grad_norm": 0.046726103872060776,
      "learning_rate": 7.715654952076677e-05,
      "loss": 0.1229,
      "step": 1540
    },
    {
      "epoch": 1.246129257816402,
      "grad_norm": 0.05395743250846863,
      "learning_rate": 7.555910543130991e-05,
      "loss": 0.1235,
      "step": 1560
    },
    {
      "epoch": 1.2621116771551293,
      "grad_norm": 0.04992886260151863,
      "learning_rate": 7.396166134185304e-05,
      "loss": 0.1243,
      "step": 1580
    },
    {
      "epoch": 1.2780940964938567,
      "grad_norm": 0.04365503042936325,
      "learning_rate": 7.236421725239617e-05,
      "loss": 0.1232,
      "step": 1600
    },
    {
      "epoch": 1.2940765158325842,
      "grad_norm": 0.05213708430528641,
      "learning_rate": 7.07667731629393e-05,
      "loss": 0.1215,
      "step": 1620
    },
    {
      "epoch": 1.3100589351713117,
      "grad_norm": 0.04649743437767029,
      "learning_rate": 6.916932907348244e-05,
      "loss": 0.1148,
      "step": 1640
    },
    {
      "epoch": 1.326041354510039,
      "grad_norm": 0.04342585429549217,
      "learning_rate": 6.757188498402556e-05,
      "loss": 0.1197,
      "step": 1660
    },
    {
      "epoch": 1.3420237738487664,
      "grad_norm": 0.038179244846105576,
      "learning_rate": 6.597444089456869e-05,
      "loss": 0.1183,
      "step": 1680
    },
    {
      "epoch": 1.3580061931874938,
      "grad_norm": 0.04560172185301781,
      "learning_rate": 6.437699680511182e-05,
      "loss": 0.124,
      "step": 1700
    },
    {
      "epoch": 1.373988612526221,
      "grad_norm": 0.04964372515678406,
      "learning_rate": 6.277955271565496e-05,
      "loss": 0.1235,
      "step": 1720
    },
    {
      "epoch": 1.3899710318649485,
      "grad_norm": 0.04980461299419403,
      "learning_rate": 6.118210862619808e-05,
      "loss": 0.1214,
      "step": 1740
    },
    {
      "epoch": 1.405953451203676,
      "grad_norm": 0.044049788266420364,
      "learning_rate": 5.958466453674122e-05,
      "loss": 0.115,
      "step": 1760
    },
    {
      "epoch": 1.4219358705424034,
      "grad_norm": 0.042757317423820496,
      "learning_rate": 5.7987220447284354e-05,
      "loss": 0.1133,
      "step": 1780
    },
    {
      "epoch": 1.4379182898811307,
      "grad_norm": 0.04400494322180748,
      "learning_rate": 5.6389776357827484e-05,
      "loss": 0.1188,
      "step": 1800
    },
    {
      "epoch": 1.4539007092198581,
      "grad_norm": 0.04899273067712784,
      "learning_rate": 5.479233226837061e-05,
      "loss": 0.1196,
      "step": 1820
    },
    {
      "epoch": 1.4698831285585856,
      "grad_norm": 0.04923180118203163,
      "learning_rate": 5.3194888178913736e-05,
      "loss": 0.1184,
      "step": 1840
    },
    {
      "epoch": 1.4858655478973128,
      "grad_norm": 0.04409048333764076,
      "learning_rate": 5.159744408945687e-05,
      "loss": 0.1154,
      "step": 1860
    },
    {
      "epoch": 1.5018479672360403,
      "grad_norm": 0.05046411603689194,
      "learning_rate": 5e-05,
      "loss": 0.1167,
      "step": 1880
    },
    {
      "epoch": 1.5178303865747678,
      "grad_norm": 0.046235062181949615,
      "learning_rate": 4.840255591054313e-05,
      "loss": 0.1229,
      "step": 1900
    },
    {
      "epoch": 1.5338128059134952,
      "grad_norm": 0.06493164598941803,
      "learning_rate": 4.680511182108626e-05,
      "loss": 0.1142,
      "step": 1920
    },
    {
      "epoch": 1.5497952252522227,
      "grad_norm": 0.04519805312156677,
      "learning_rate": 4.520766773162939e-05,
      "loss": 0.1151,
      "step": 1940
    },
    {
      "epoch": 1.56577764459095,
      "grad_norm": 0.048331160098314285,
      "learning_rate": 4.361022364217253e-05,
      "loss": 0.1128,
      "step": 1960
    },
    {
      "epoch": 1.5817600639296774,
      "grad_norm": 0.04520821571350098,
      "learning_rate": 4.201277955271566e-05,
      "loss": 0.1193,
      "step": 1980
    },
    {
      "epoch": 1.5977424832684046,
      "grad_norm": 0.047359973192214966,
      "learning_rate": 4.041533546325879e-05,
      "loss": 0.1135,
      "step": 2000
    },
    {
      "epoch": 1.613724902607132,
      "grad_norm": 0.051909491419792175,
      "learning_rate": 3.8817891373801916e-05,
      "loss": 0.1267,
      "step": 2020
    },
    {
      "epoch": 1.6297073219458595,
      "grad_norm": 0.05516117811203003,
      "learning_rate": 3.722044728434505e-05,
      "loss": 0.118,
      "step": 2040
    },
    {
      "epoch": 1.645689741284587,
      "grad_norm": 0.044445838779211044,
      "learning_rate": 3.562300319488818e-05,
      "loss": 0.1124,
      "step": 2060
    },
    {
      "epoch": 1.6616721606233145,
      "grad_norm": 0.047700170427560806,
      "learning_rate": 3.402555910543131e-05,
      "loss": 0.1148,
      "step": 2080
    },
    {
      "epoch": 1.6776545799620417,
      "grad_norm": 0.05004572123289108,
      "learning_rate": 3.242811501597444e-05,
      "loss": 0.1221,
      "step": 2100
    },
    {
      "epoch": 1.6936369993007692,
      "grad_norm": 0.04981271177530289,
      "learning_rate": 3.083067092651757e-05,
      "loss": 0.1161,
      "step": 2120
    },
    {
      "epoch": 1.7096194186394964,
      "grad_norm": 0.050071023404598236,
      "learning_rate": 2.9233226837060707e-05,
      "loss": 0.1122,
      "step": 2140
    },
    {
      "epoch": 1.7256018379782239,
      "grad_norm": 0.0473821647465229,
      "learning_rate": 2.7635782747603834e-05,
      "loss": 0.1192,
      "step": 2160
    },
    {
      "epoch": 1.7415842573169513,
      "grad_norm": 0.03811733424663544,
      "learning_rate": 2.6038338658146967e-05,
      "loss": 0.122,
      "step": 2180
    },
    {
      "epoch": 1.7575666766556788,
      "grad_norm": 0.051693595945835114,
      "learning_rate": 2.44408945686901e-05,
      "loss": 0.1201,
      "step": 2200
    },
    {
      "epoch": 1.7735490959944062,
      "grad_norm": 0.04528583958745003,
      "learning_rate": 2.284345047923323e-05,
      "loss": 0.1207,
      "step": 2220
    },
    {
      "epoch": 1.7895315153331337,
      "grad_norm": 0.04809381440281868,
      "learning_rate": 2.124600638977636e-05,
      "loss": 0.1229,
      "step": 2240
    },
    {
      "epoch": 1.805513934671861,
      "grad_norm": 0.0423584021627903,
      "learning_rate": 1.964856230031949e-05,
      "loss": 0.1228,
      "step": 2260
    },
    {
      "epoch": 1.8214963540105884,
      "grad_norm": 0.055846039205789566,
      "learning_rate": 1.805111821086262e-05,
      "loss": 0.1194,
      "step": 2280
    },
    {
      "epoch": 1.8374787733493156,
      "grad_norm": 0.047921109944581985,
      "learning_rate": 1.645367412140575e-05,
      "loss": 0.117,
      "step": 2300
    },
    {
      "epoch": 1.853461192688043,
      "grad_norm": 0.054378967732191086,
      "learning_rate": 1.485623003194888e-05,
      "loss": 0.1237,
      "step": 2320
    },
    {
      "epoch": 1.8694436120267706,
      "grad_norm": 0.04644308611750603,
      "learning_rate": 1.3258785942492014e-05,
      "loss": 0.1194,
      "step": 2340
    },
    {
      "epoch": 1.885426031365498,
      "grad_norm": 0.051489125937223434,
      "learning_rate": 1.1661341853035145e-05,
      "loss": 0.1223,
      "step": 2360
    },
    {
      "epoch": 1.9014084507042255,
      "grad_norm": 0.0443466380238533,
      "learning_rate": 1.0063897763578276e-05,
      "loss": 0.1272,
      "step": 2380
    },
    {
      "epoch": 1.9173908700429527,
      "grad_norm": 0.04039420932531357,
      "learning_rate": 8.466453674121406e-06,
      "loss": 0.1121,
      "step": 2400
    },
    {
      "epoch": 1.9333732893816802,
      "grad_norm": 0.05466316267848015,
      "learning_rate": 6.869009584664538e-06,
      "loss": 0.1143,
      "step": 2420
    },
    {
      "epoch": 1.9493557087204074,
      "grad_norm": 0.04915708675980568,
      "learning_rate": 5.2715654952076674e-06,
      "loss": 0.1185,
      "step": 2440
    },
    {
      "epoch": 1.9653381280591349,
      "grad_norm": 0.050028689205646515,
      "learning_rate": 3.6741214057507987e-06,
      "loss": 0.1135,
      "step": 2460
    },
    {
      "epoch": 1.9813205473978623,
      "grad_norm": 0.041089240461587906,
      "learning_rate": 2.0766773162939296e-06,
      "loss": 0.1114,
      "step": 2480
    },
    {
      "epoch": 1.9973029667365898,
      "grad_norm": 0.05315922573208809,
      "learning_rate": 4.792332268370607e-07,
      "loss": 0.1231,
      "step": 2500
    }
  ],
  "logging_steps": 20,
  "max_steps": 2504,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8.148753989228298e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
